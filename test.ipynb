{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM6M5ZXnvNlTzy563uc7rU6",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/awb-mj/brd-generation/blob/test/test.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "V1E2cW9GeGNb",
        "outputId": "29b4e38a-43b9-4f17-c582-8f0888d761c9"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e616c767-21c3-4c2e-a85b-dc25f6fe3481\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-e616c767-21c3-4c2e-a85b-dc25f6fe3481\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving brd-generation-91eaf7b1a023.json to brd-generation-91eaf7b1a023.json\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "SERVICE_ACCOUNT_FILE = list(uploaded.keys())[0]  # Gets the uploaded JSON file\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = SERVICE_ACCOUNT_FILE\n"
      ],
      "metadata": {
        "id": "hlGDF9NDff_F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!gcloud auth activate-service-account --key-file={SERVICE_ACCOUNT_FILE}\n",
        "!gcloud config list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1PKjZTvHfomJ",
        "outputId": "04c45a34-ac90-44c6-fe9f-670128bc37ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activated service account credentials for: [langchain@brd-generation.iam.gserviceaccount.com]\n",
            "[component_manager]\n",
            "disable_update_check = True\n",
            "[compute]\n",
            "gce_metadata_read_timeout_sec = 0\n",
            "[core]\n",
            "account = langchain@brd-generation.iam.gserviceaccount.com\n",
            "\n",
            "Your active configuration is: [default]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain-google-genai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "fQcUXXcAQQqI",
        "outputId": "8042c9f8-2dd6-4920-9a95-41f001a04c08"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting langchain-google-genai\n",
            "  Downloading langchain_google_genai-2.1.4-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from langchain-google-genai)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting google-ai-generativelanguage<0.7.0,>=0.6.18 (from langchain-google-genai)\n",
            "  Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl.metadata (9.8 kB)\n",
            "Requirement already satisfied: langchain-core<0.4.0,>=0.3.52 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (0.3.59)\n",
            "Requirement already satisfied: pydantic<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain-google-genai) (2.11.4)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.24.2)\n",
            "Requirement already satisfied: google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.38.0)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.26.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.20.2 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.29.4)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.125 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.3.42)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.33)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (6.0.2)\n",
            "Requirement already satisfied: packaging<25,>=23.2 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (24.2)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (4.13.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2->langchain-google-genai) (0.4.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.70.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.32.3)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (4.9.1)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (3.0.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.23.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (0.16.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth!=2.24.0,!=2.25.0,<3.0.0,>=2.14.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (0.6.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0,>=1.34.1->google-ai-generativelanguage<0.7.0,>=0.6.18->langchain-google-genai) (2.4.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.125->langchain-core<0.4.0,>=0.3.52->langchain-google-genai) (1.3.1)\n",
            "Downloading langchain_google_genai-2.1.4-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.3/44.3 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading google_ai_generativelanguage-0.6.18-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m24.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: filetype, google-ai-generativelanguage, langchain-google-genai\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.15\n",
            "    Uninstalling google-ai-generativelanguage-0.6.15:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.15\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-generativeai 0.8.5 requires google-ai-generativelanguage==0.6.15, but you have google-ai-generativelanguage 0.6.18 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed filetype-1.2.0 google-ai-generativelanguage-0.6.18 langchain-google-genai-2.1.4\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "dea7a469adbb4113bdc155031717c347"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test Case 1: Connect LangChain with Gemini via ChatGoogleGenerativeAI\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnableSequence\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Setup Gemini\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
        "\n",
        "# Prompt template\n",
        "prompt = PromptTemplate.from_template(\"Give me 3 bullet points about {topic}, without any markdown or formatting\")\n",
        "\n",
        "# Use RunnableSequence instead of LLMChain\n",
        "chain = prompt | llm\n",
        "\n",
        "# Invoke instead of run\n",
        "response = chain.invoke({\"topic\": \"Weaviate vector store\"})\n",
        "print(response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HCbUVRmGfymz",
        "outputId": "3180be9c-c5e8-446d-f342-f7054a70ece4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Weaviate is a cloud-native vector database.\n",
            "Weaviate supports hybrid search, combining vector and textual search.\n",
            "Weaviate offers GraphQL API for easy data interaction.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Assuming you uploaded the JSON file\n",
        "SERVICE_ACCOUNT_FILE = \"brd-generation-91eaf7b1a023.json\"\n",
        "\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = SERVICE_ACCOUNT_FILE\n",
        "\n",
        "# Verify access to Google Cloud project\n",
        "!gcloud auth activate-service-account --key-file={SERVICE_ACCOUNT_FILE}\n",
        "!gcloud config list"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y0r4cSO3eMmd",
        "outputId": "a2c3e1d3-9962-49c3-bc7e-8f7cef45f448"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Activated service account credentials for: [langchain@brd-generation.iam.gserviceaccount.com]\n",
            "[component_manager]\n",
            "disable_update_check = True\n",
            "[compute]\n",
            "gce_metadata_read_timeout_sec = 0\n",
            "[core]\n",
            "account = langchain@brd-generation.iam.gserviceaccount.com\n",
            "\n",
            "Your active configuration is: [default]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()  # Choose a .txt or .pdf file\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "kHg0QVODeYjs",
        "outputId": "23c67d9f-6c3e-400d-a376-f7e890033107"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-d949bb41-35c5-4177-a033-420e2b89bf02\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-d949bb41-35c5-4177-a033-420e2b89bf02\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving sample_brd.txt to sample_brd.txt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q langchain-community pypdf"
      ],
      "metadata": {
        "id": "mmkYx4smenVD",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7f61d8d2-0354-49df-82c5-fb23b616a41d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/2.5 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.7/2.5 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m45.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m303.4/303.4 kB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.9/50.9 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST CASE 2A: Load Document from Local Filesystem (e.g., .pdf or .txt)\n",
        "from langchain_community.document_loaders import PyPDFLoader, TextLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "# Replace with your uploaded file name\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "# Load based on file type\n",
        "if file_name.endswith(\".pdf\"):\n",
        "    loader = PyPDFLoader(file_name)\n",
        "elif file_name.endswith(\".txt\"):\n",
        "    loader = TextLoader(file_name)\n",
        "else:\n",
        "    raise ValueError(\"Unsupported file type\")\n",
        "\n",
        "# Load and split into chunks\n",
        "documents = loader.load()\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)\n",
        "docs = splitter.split_documents(documents)\n",
        "\n",
        "print(f\"Loaded {len(docs)} document chunks.\")\n",
        "print(docs[0].page_content[:300])  # Preview first chunk"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t1rTMiaWlP85",
        "outputId": "4b95f26a-6df4-4ccd-e868-73412a285ce3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loaded 3 document chunks.\n",
            "Project Overview:\n",
            "The new Inventory Management System (IMS) aims to streamline stock tracking, reduce manual errors, and improve reporting capabilities for our retail chain.\n",
            "\n",
            "Goals:\n",
            "- Automate stock level updates in real-time.\n",
            "- Provide alerts for low inventory.\n",
            "- Enable detailed sales and inventory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST CASE 2B: Load Document from Google Cloud Storage\n",
        "!pip install -q langchain-community google-cloud-storage\n",
        "!pip install -q langchain-community google-cloud-storage unstructured"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HMrhVxh6mJmo",
        "outputId": "1a9ec35b-c943-4eb9-fe92-5ddb7794c935"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/981.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━\u001b[0m \u001b[32m604.2/981.5 kB\u001b[0m \u001b[31m19.4 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m981.5/981.5 kB\u001b[0m \u001b[31m18.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m48.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m590.6/590.6 kB\u001b[0m \u001b[31m34.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m167.6/167.6 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m51.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.1/192.1 kB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m114.6/114.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Building wheel for langdetect (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "\n",
        "# Update with your actual filename\n",
        "service_account_path = \"brd-generation-91eaf7b1a023.json\"\n",
        "\n",
        "os.environ[\"GOOGLE_APPLICATION_CREDENTIALS\"] = service_account_path\n",
        "\n",
        "# Test with google-cloud-storage\n",
        "from google.cloud import storage\n",
        "\n",
        "client = storage.Client()\n",
        "buckets = list(client.list_buckets())\n",
        "\n",
        "print(\"✅ Authenticated successfully.\")\n",
        "print(\"Available buckets:\", [bucket.name for bucket in buckets])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jz2h_ZGEqgS9",
        "outputId": "d506c19a-a8b1-4a53-a750-ac3c76296c95"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Authenticated successfully.\n",
            "Available buckets: ['mj-test-langchain']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import GCSFileLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from google.cloud import storage  # GCP storage client\n",
        "\n",
        "# --- CONFIGURATION ---\n",
        "BUCKET_NAME = \"mj-test-langchain\"\n",
        "BLOB_NAME = \"sample_brd.txt\"\n",
        "PROJECT_ID = \"brd-generation\"\n",
        "\n",
        "# --- CHECK FOR FILE EXISTENCE ---\n",
        "client = storage.Client(project=PROJECT_ID)\n",
        "bucket = client.get_bucket(BUCKET_NAME)\n",
        "blob_object = bucket.get_blob(BLOB_NAME)\n",
        "\n",
        "if blob_object is None:\n",
        "    print(f\"❌ Error: Blob '{BLOB_NAME}' not found in bucket '{BUCKET_NAME}'. Please check the path.\")\n",
        "else:\n",
        "    print(f\"✅ Blob '{BLOB_NAME}' found. Proceeding to load and split...\\n\")\n",
        "\n",
        "    # Load file using LangChain GCS loader\n",
        "    loader = GCSFileLoader(bucket=BUCKET_NAME, blob=BLOB_NAME, project_name=PROJECT_ID)\n",
        "    documents = loader.load()\n",
        "\n",
        "    # Use fine-grained chunking (sentence-level)\n",
        "    splitter = RecursiveCharacterTextSplitter(\n",
        "        chunk_size=200,\n",
        "        chunk_overlap=20,\n",
        "        separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
        "    )\n",
        "\n",
        "    # Split the document into small chunks\n",
        "    docs = splitter.split_documents(documents)\n",
        "\n",
        "    # Print chunk info for debugging\n",
        "    print(f\"✅ Loaded {len(docs)} chunks from GCS\")\n",
        "\n",
        "    for i, d in enumerate(docs):\n",
        "        print(f\"\\n--- Chunk {i+1} ---\")\n",
        "        print(d.page_content)\n",
        "\n",
        "    # Optional: preview the original document\n",
        "    print(\"\\n📄 Raw document length:\", len(documents[0].page_content))\n",
        "    print(\"\\n📄 Document preview:\\n\", documents[0].page_content[:300])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tacIbG0mmq51",
        "outputId": "b6d43884-930f-465a-b795-b40f638a6ae8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Blob 'sample_brd.txt' found. Proceeding to load and split...\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-12-8e8b2e846e02>:21: LangChainDeprecationWarning: The class `GCSFileLoader` was deprecated in LangChain 0.0.32 and will be removed in 1.0. An updated version of the class exists in the :class:`~langchain-google-community package and should be used instead. To use it run `pip install -U :class:`~langchain-google-community` and import as `from :class:`~langchain_google_community import GCSFileLoader``.\n",
            "  loader = GCSFileLoader(bucket=BUCKET_NAME, blob=BLOB_NAME, project_name=PROJECT_ID)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Loaded 6 chunks from GCS\n",
            "\n",
            "--- Chunk 1 ---\n",
            "Project Overview: The new Inventory Management System (IMS) aims to streamline stock tracking, reduce manual errors, and improve reporting capabilities for our retail chain.\n",
            "\n",
            "--- Chunk 2 ---\n",
            "Goals: - Automate stock level updates in real-time. - Provide alerts for low inventory. - Enable detailed sales and inventory reports.\n",
            "\n",
            "--- Chunk 3 ---\n",
            "Functional Requirements: 1. The system shall track inventory levels by product and location. 2. Users shall be able to create and modify stock entries. 3\n",
            "\n",
            "--- Chunk 4 ---\n",
            ". 3. The system shall generate daily reports emailed to managers. 4. Alerts shall be sent when stock drops below predefined thresholds.\n",
            "\n",
            "--- Chunk 5 ---\n",
            "Non-Functional Requirements: - The system shall be accessible via web and mobile. - Response time for stock queries shall be under 2 seconds. - Data backups shall occur every 24 hours.\n",
            "\n",
            "--- Chunk 6 ---\n",
            "Notes: - Integration with existing POS systems will be handled in Phase 2. - User authentication will use OAuth 2.0 standards.\n",
            "\n",
            "📄 Raw document length: 910\n",
            "\n",
            "📄 Document preview:\n",
            " Project Overview: The new Inventory Management System (IMS) aims to streamline stock tracking, reduce manual errors, and improve reporting capabilities for our retail chain.\n",
            "\n",
            "Goals: - Automate stock level updates in real-time. - Provide alerts for low inventory. - Enable detailed sales and inventory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#TEST 3a. Use FAISS (in-memory, great for local dev/test)\n",
        "!pip install faiss-cpu langchain google-generativeai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "dTC8CYsOz0mC",
        "outputId": "0ba3fbc5-3258-46c8-9852-4cd947fc39d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting faiss-cpu\n",
            "  Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Requirement already satisfied: google-generativeai in /usr/local/lib/python3.11/dist-packages (0.8.5)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (2.0.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from faiss-cpu) (24.2)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.59)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting google-ai-generativelanguage==0.6.15 (from google-generativeai)\n",
            "  Downloading google_ai_generativelanguage-0.6.15-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.24.2)\n",
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.169.0)\n",
            "Requirement already satisfied: google-auth>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (2.38.0)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (5.29.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.11/dist-packages (from google-generativeai) (4.13.2)\n",
            "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core->google-generativeai) (1.70.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.28.1)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2025.4.26)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
            "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (4.9.0)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (0.16.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith<0.4,>=0.1.17->langchain) (1.3.1)\n",
            "Downloading faiss_cpu-1.11.0-cp311-cp311-manylinux_2_28_x86_64.whl (31.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.3/31.3 MB\u001b[0m \u001b[31m18.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading google_ai_generativelanguage-0.6.15-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m23.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: faiss-cpu, google-ai-generativelanguage\n",
            "  Attempting uninstall: google-ai-generativelanguage\n",
            "    Found existing installation: google-ai-generativelanguage 0.6.18\n",
            "    Uninstalling google-ai-generativelanguage-0.6.18:\n",
            "      Successfully uninstalled google-ai-generativelanguage-0.6.18\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-google-genai 2.1.4 requires google-ai-generativelanguage<0.7.0,>=0.6.18, but you have google-ai-generativelanguage 0.6.15 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed faiss-cpu-1.11.0 google-ai-generativelanguage-0.6.15\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "google"
                ]
              },
              "id": "899484bebc9947448f628fa04f811c70"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "from langchain.vectorstores import FAISS\n",
        "\n",
        "# Set your API Key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = \"AIzaSyD2npvrg5q5X30B__xaqho26hBl-zZ1jNo\"  # Replace with your key\n",
        "\n",
        "# Initialize the embedding model\n",
        "embedding_model = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\")"
      ],
      "metadata": {
        "id": "6galrh-w4ppD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Vectorize the chunks you previously created\n",
        "db = FAISS.from_documents(docs, embedding_model)\n",
        "\n",
        "print(f\"Total vectors stored: {db.index.ntotal}\")\n",
        "embedding = embedding_model.embed_query(\"sample test\")\n",
        "print(embedding[:5])  # Show the first few dimensions\n",
        "print(db.docstore._dict.keys())  # Document IDs\n",
        "\n",
        "# Save the vector store locally if needed\n",
        "db.save_local(\"faiss_index\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZwV28hta60fW",
        "outputId": "d34532c9-bff7-4b90-9edd-45a61b4bc80c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total vectors stored: 6\n",
            "[0.022720204666256905, -0.02944863587617874, -0.012011196464300156, -0.04096759483218193, 0.033677540719509125]\n",
            "dict_keys(['cdbd691e-ef42-48cb-bd76-e70314e1861f', '0cfeb60f-6964-4b13-80ac-8f268f5dd61b', 'e30ddae7-2ea1-44d3-a552-db0d0070fd6b', '8f8baa75-8069-4611-9581-3f598e20d63b', '9e53c551-3169-483c-bbef-fa90e15ca2f4', '762ceb84-a851-47b2-9d41-ae500d3798ba'])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Euclidean or Cosine distance\n",
        "query = \"Which authentication standard will be used, and in which project phase is POS integration handled?\"\n",
        "results = db.similarity_search_with_score(query, k=1)\n",
        "\n",
        "for i, (res, score) in enumerate(results):\n",
        "  if score > 0.75:\n",
        "    print(\"⚠️ No relevant result found. Please refine your query.\")\n",
        "  else:\n",
        "    print(f\"\\n--- Result {i+1} (Score: {score:.4f}) ---\")\n",
        "    print(res.page_content)\n",
        "#✅ Lower score = more similar"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CEp0Yh-X64wI",
        "outputId": "57ab176b-e2a5-4fb5-9974-f17fd900cba0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "--- Result 1 (Score: 0.5786) ---\n",
            "Notes: - Integration with existing POS systems will be handled in Phase 2. - User authentication will use OAuth 2.0 standards.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test 3b Use Weaviate (production-grade vector store, cloud-native)\n",
        "# 📦 1. Install necessary packages\n",
        "!pip install weaviate-client>=3.26.7,<4.0.0 langchain google-cloud-storage langchain-community\n",
        "\n",
        "# Install necessary packages\n",
        "!pip install -U langchain langchain-weaviate weaviate-client"
      ],
      "metadata": {
        "id": "z6814NNEzclY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "111b99ca-4499-4048-a98d-6b5f663c4f2a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: 4.0.0: No such file or directory\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.25)\n",
            "Collecting langchain-weaviate\n",
            "  Downloading langchain_weaviate-0.0.4-py3-none-any.whl.metadata (2.7 kB)\n",
            "Collecting weaviate-client\n",
            "  Downloading weaviate_client-4.14.4-py3-none-any.whl.metadata (3.7 kB)\n",
            "Requirement already satisfied: langchain-core<1.0.0,>=0.3.58 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.59)\n",
            "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.8 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.8)\n",
            "Requirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.42)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.32.3)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.11/dist-packages (from langchain) (6.0.2)\n",
            "Collecting numpy<2.0.0,>=1.26.2 (from langchain-weaviate)\n",
            "  Downloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: simsimd<7.0.0,>=6.2.1 in /usr/local/lib/python3.11/dist-packages (from langchain-weaviate) (6.2.1)\n",
            "Requirement already satisfied: httpx<0.29.0,>=0.26.0 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (0.28.1)\n",
            "Collecting validators==0.34.0 (from weaviate-client)\n",
            "  Downloading validators-0.34.0-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting authlib<1.3.2,>=1.2.1 (from weaviate-client)\n",
            "  Downloading Authlib-1.3.1-py2.py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: grpcio<2.0.0,>=1.66.2 in /usr/local/lib/python3.11/dist-packages (from weaviate-client) (1.71.0)\n",
            "Collecting grpcio-tools<2.0.0,>=1.66.2 (from weaviate-client)\n",
            "  Downloading grpcio_tools-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.3 kB)\n",
            "Collecting grpcio-health-checking<2.0.0,>=1.66.2 (from weaviate-client)\n",
            "  Downloading grpcio_health_checking-1.71.0-py3-none-any.whl.metadata (1.0 kB)\n",
            "Collecting deprecation<3.0.0,>=2.1.0 (from weaviate-client)\n",
            "  Downloading deprecation-2.1.0-py2.py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: cryptography in /usr/local/lib/python3.11/dist-packages (from authlib<1.3.2,>=1.2.1->weaviate-client) (43.0.3)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from deprecation<3.0.0,>=2.1.0->weaviate-client) (24.2)\n",
            "Requirement already satisfied: protobuf<6.0dev,>=5.26.1 in /usr/local/lib/python3.11/dist-packages (from grpcio-health-checking<2.0.0,>=1.66.2->weaviate-client) (5.29.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from grpcio-tools<2.0.0,>=1.66.2->weaviate-client) (75.2.0)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (4.9.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.11/dist-packages (from httpx<0.29.0,>=0.26.0->weaviate-client) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<0.29.0,>=0.26.0->weaviate-client) (0.16.0)\n",
            "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (9.1.2)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (1.33)\n",
            "Requirement already satisfied: typing-extensions>=4.7 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.58->langchain) (4.13.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (3.10.18)\n",
            "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (1.0.0)\n",
            "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith<0.4,>=0.1.17->langchain) (0.23.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (3.4.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2->langchain) (2.4.0)\n",
            "Requirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.2.2)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.58->langchain) (3.0.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<0.29.0,>=0.26.0->weaviate-client) (1.3.1)\n",
            "Requirement already satisfied: cffi>=1.12 in /usr/local/lib/python3.11/dist-packages (from cryptography->authlib<1.3.2,>=1.2.1->weaviate-client) (1.17.1)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from cffi>=1.12->cryptography->authlib<1.3.2,>=1.2.1->weaviate-client) (2.22)\n",
            "Downloading langchain_weaviate-0.0.4-py3-none-any.whl (10 kB)\n",
            "Downloading weaviate_client-4.14.4-py3-none-any.whl (437 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m437.0/437.0 kB\u001b[0m \u001b[31m13.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading validators-0.34.0-py3-none-any.whl (43 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading Authlib-1.3.1-py2.py3-none-any.whl (223 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.8/223.8 kB\u001b[0m \u001b[31m17.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading deprecation-2.1.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading grpcio_health_checking-1.71.0-py3-none-any.whl (18 kB)\n",
            "Downloading grpcio_tools-1.71.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m51.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-1.26.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m79.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: validators, numpy, grpcio-tools, grpcio-health-checking, deprecation, authlib, weaviate-client, langchain-weaviate\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 2.0.2\n",
            "    Uninstalling numpy-2.0.2:\n",
            "      Successfully uninstalled numpy-2.0.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed authlib-1.3.1 deprecation-2.1.0 grpcio-health-checking-1.71.0 grpcio-tools-1.71.0 langchain-weaviate-0.0.4 numpy-1.26.4 validators-0.34.0 weaviate-client-4.14.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "from langchain_weaviate.vectorstores import WeaviateVectorStore\n",
        "from langchain_community.document_loaders import GCSFileLoader\n",
        "# Corrected the typo in the import statement\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "# Import GoogleGenerativeAIEmbeddings for embeddings\n",
        "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
        "import weaviate\n",
        "from weaviate.auth import AuthApiKey\n",
        "\n",
        "# Set environment variables\n",
        "# Ensure this matches the key you used for the FAISS test case\n",
        "google_api_key = \"AIzaSyD2npvrg5q5X30B__xaqho26hBl-zZ1jNo\"  # Replace with your actual Gemini API key\n",
        "os.environ[\"GOOGLE_API_KEY\"] = google_api_key\n",
        "\n",
        "# GCS file information\n",
        "BUCKET_NAME = \"mj-test-langchain\"\n",
        "BLOB_NAME = \"sample_brd.txt\"\n",
        "PROJECT_ID = \"brd-generation\"\n",
        "\n",
        "# Load and split documents\n",
        "loader = GCSFileLoader(bucket=BUCKET_NAME, blob=BLOB_NAME, project_name=PROJECT_ID)\n",
        "documents = loader.load()\n",
        "\n",
        "# Use the corrected class name\n",
        "splitter = RecursiveCharacterTextSplitter(\n",
        "    chunk_size=200,\n",
        "    chunk_overlap=20,\n",
        "    separators=[\"\\n\\n\", \"\\n\", \".\", \" \"]\n",
        ")\n",
        "docs = splitter.split_documents(documents)\n",
        "\n",
        "# Initialize embeddings - Pass the API key directly\n",
        "# Use GoogleGenerativeAIEmbeddings as GooglePalmEmbeddings is deprecated\n",
        "embedding = GoogleGenerativeAIEmbeddings(model=\"models/embedding-001\", google_api_key=google_api_key)\n",
        "\n",
        "\n",
        "# Connect to Weaviate Cloud\n",
        "client = weaviate.connect_to_weaviate_cloud(\n",
        "    cluster_url=\"https://h4tnl67zr5yopm0xp7asg.c0.asia-southeast1.gcp.weaviate.cloud\",\n",
        "    auth_credentials=AuthApiKey(api_key=\"uNK224bKTuTBFeIPcwXCsXlx2cfoLxerbhVp\")\n",
        ")\n",
        "\n",
        "# Create and populate the vector store\n",
        "vectorstore = WeaviateVectorStore.from_documents(\n",
        "    documents=docs,\n",
        "    embedding=embedding,\n",
        "    client=client,\n",
        "    index_name=\"LangchainDocs\",\n",
        "    text_key=\"content\"\n",
        ")\n",
        "\n",
        "print(\"✅ Documents successfully indexed in Weaviate. You are able to embed data successfully.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c895uy3vBioU",
        "outputId": "be6921ca-3ac1-4212-90a6-576159713bc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Documents successfully indexed in Weaviate. You are able to embed data successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Now, run a semantic query with scores\n",
        "#Cosine similarity scores, where 1.0 means perfect similarity (identical vectors) and lower values mean less similarity.\n",
        "query = \"What is the primary aim of the new Inventory Management System (IMS)?\"\n",
        "\n",
        "results_with_scores = vectorstore.similarity_search_with_score(query, k=3)  # Get top 3 closest docs + scores\n",
        "\n",
        "print(\"\\n=== Semantic Search Results with Scores ===\")\n",
        "for i, (doc, score) in enumerate(results_with_scores):\n",
        "    print(f\"\\nResult {i+1} (Score: {score:.4f}):\\n{doc.page_content}\\n\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WgddJNWJI4dz",
        "outputId": "b4edd4fe-fdcc-45e8-9a62-0319464ea4ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Semantic Search Results with Scores ===\n",
            "\n",
            "Result 1 (Score: 1.0000):\n",
            "Project Overview: The new Inventory Management System (IMS) aims to streamline stock tracking, reduce manual errors, and improve reporting capabilities for our retail chain.\n",
            "\n",
            "\n",
            "Result 2 (Score: 1.0000):\n",
            "Project Overview: The new Inventory Management System (IMS) aims to streamline stock tracking, reduce manual errors, and improve reporting capabilities for our retail chain.\n",
            "\n",
            "\n",
            "Result 3 (Score: 1.0000):\n",
            "Project Overview: The new Inventory Management System (IMS) aims to streamline stock tracking, reduce manual errors, and improve reporting capabilities for our retail chain.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 4A: Retrieve relevant documents from your vector store (Weaviate or FAISS)\n",
        "query = \"How will the IMS send daily reports?\"\n",
        "\n",
        "# Retrieve top 3 relevant document chunks + scores from Weaviate\n",
        "results_with_scores = vectorstore.similarity_search_with_score(query, k=3)\n",
        "\n",
        "print(\"\\n=== Retrieved Chunks for Context ===\")\n",
        "retrieved_texts = []\n",
        "for i, (doc, score) in enumerate(results_with_scores):\n",
        "    print(f\"\\nChunk {i+1} (score: {score:.4f}): {doc.page_content[:200]}...\")  # preview first 200 chars\n",
        "    retrieved_texts.append(doc.page_content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G9yXsIvZwhBg",
        "outputId": "23aad90d-3973-4067-e790-f17cd4d45056"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Retrieved Chunks for Context ===\n",
            "\n",
            "Chunk 1 (score: 1.0000): . 3. The system shall generate daily reports emailed to managers. 4. Alerts shall be sent when stock drops below predefined thresholds....\n",
            "\n",
            "Chunk 2 (score: 1.0000): . 3. The system shall generate daily reports emailed to managers. 4. Alerts shall be sent when stock drops below predefined thresholds....\n",
            "\n",
            "Chunk 3 (score: 1.0000): . 3. The system shall generate daily reports emailed to managers. 4. Alerts shall be sent when stock drops below predefined thresholds....\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 4B: Combine retrieved chunks into a prompt for the LLM. Prepare a prompt with retrieved context + query\n",
        "# Combine the retrieved chunks into one context string\n",
        "context = \"\\n\\n---\\n\\n\".join(retrieved_texts)\n",
        "\n",
        "# Create a prompt template that includes the context and user query\n",
        "prompt_text = f\"\"\"\n",
        "You are an expert assistant. Use the following context to answer the question below.\n",
        "If the answer is not in the context, say 'I don't know.'\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\n",
        "Question:\n",
        "{query}\n",
        "\n",
        "Answer:\n",
        "\"\"\"\n",
        "print(prompt_text)  # Optional: see your prompt\n"
      ],
      "metadata": {
        "id": "031xH1KQODsb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74bee997-6d2f-4246-a7f2-495f1ccf4cee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "You are an expert assistant. Use the following context to answer the question below.\n",
            "If the answer is not in the context, say 'I don't know.'\n",
            "\n",
            "Context:\n",
            ". 3. The system shall generate daily reports emailed to managers. 4. Alerts shall be sent when stock drops below predefined thresholds.\n",
            "\n",
            "---\n",
            "\n",
            ". 3. The system shall generate daily reports emailed to managers. 4. Alerts shall be sent when stock drops below predefined thresholds.\n",
            "\n",
            "---\n",
            "\n",
            ". 3. The system shall generate daily reports emailed to managers. 4. Alerts shall be sent when stock drops below predefined thresholds.\n",
            "\n",
            "Question:\n",
            "How will the IMS send daily reports?\n",
            "\n",
            "Answer:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 4C: Run the prompt through an LLM (Gemini by Google)\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_core.runnables import RunnableSequence\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "\n",
        "# Initialize Gemini (LLM)\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
        "\n",
        "# Prepare prompt template (using raw string for flexibility)\n",
        "prompt_template = PromptTemplate.from_template(prompt_text)\n",
        "\n",
        "# Runnable sequence chaining prompt and LLM\n",
        "chain = prompt_template | llm\n",
        "\n",
        "# Run the chain to get the answer\n",
        "response = chain.invoke({})\n",
        "\n",
        "print(\"\\n=== Generated Answer ===\")\n",
        "print(response.content)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CtRxe3_ivtc8",
        "outputId": "f732a04e-3a80-44ba-f42c-90737059bbce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Generated Answer ===\n",
            "The IMS will send daily reports via email to managers.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6A: Define Clean Prompt Templates for Each BRD Section\n",
        "from langchain.prompts import PromptTemplate\n",
        "\n",
        "brd_section_prompts = {\n",
        "    \"Introduction\": PromptTemplate(\n",
        "        input_variables=[\"context\"],\n",
        "        template=\"\"\"\n",
        "Write a professional and formal BRD Introduction section based on the following context. Do not repeat the section name. Be clear and concise.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "    ),\n",
        "    \"Business Goals\": PromptTemplate(\n",
        "        input_variables=[\"context\"],\n",
        "        template=\"\"\"\n",
        "Based on the following context, list 3 to 5 specific business goals for the project using bold headings and concise explanations.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "    ),\n",
        "    \"Functional Requirements\": PromptTemplate(\n",
        "        input_variables=[\"context\"],\n",
        "        template=\"\"\"\n",
        "Extract 3 to 5 clear and complete functional requirements from the following context. Use numbered format and ensure each requirement is specific and actionable.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "    ),\n",
        "    \"Non-Functional Requirements\": PromptTemplate(\n",
        "        input_variables=[\"context\"],\n",
        "        template=\"\"\"\n",
        "List at least 3 non-functional requirements based on the context. Use bullets and clarify system performance, usability, reliability, etc.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "    ),\n",
        "    \"Stakeholders\": PromptTemplate(\n",
        "        input_variables=[\"context\"],\n",
        "        template=\"\"\"\n",
        "Identify key stakeholders involved in the project. Provide brief roles and responsibilities for each stakeholder group.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "    ),\n",
        "    \"Timeline\": PromptTemplate(\n",
        "        input_variables=[\"context\"],\n",
        "        template=\"\"\"\n",
        "Generate a proposed timeline with key milestones for this project. Provide dates (or weeks) and descriptions of what each milestone includes.\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "    )\n",
        "}\n"
      ],
      "metadata": {
        "id": "eXn_o4I80FkE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 6B: Use RAG to Retrieve Relevant Chunks\n",
        "\n",
        "query = \"Generate BRD content for the IMS project\"\n",
        "results = vectorstore.similarity_search_with_score(query, k=5)\n",
        "context = \"\\n\\n---\\n\\n\".join([doc.page_content for doc, _ in results])"
      ],
      "metadata": {
        "id": "iSMEqWxz43VV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6C: Generate Section Content Using Gemini\n",
        "from langchain_google_genai import ChatGoogleGenerativeAI\n",
        "import re\n",
        "\n",
        "# Instantiate the Gemini 1.5 Flash LLM\n",
        "llm = ChatGoogleGenerativeAI(model=\"gemini-1.5-flash\")\n",
        "\n",
        "# Helper to extract **bold** from markdown and return text + bold index positions\n",
        "def extract_bold_positions(text):\n",
        "    bold_positions = []\n",
        "    plain_text = \"\"\n",
        "    idx = 0\n",
        "\n",
        "    for match in re.finditer(r\"\\*\\*(.*?)\\*\\*\", text):\n",
        "        start, end = match.span()\n",
        "        bold_text = match.group(1)\n",
        "\n",
        "        # Add normal text before the bold match\n",
        "        plain_text += text[idx:start]\n",
        "        bold_start = len(plain_text)\n",
        "        plain_text += bold_text\n",
        "        bold_end = len(plain_text)\n",
        "        bold_positions.append((bold_start, bold_end))\n",
        "        idx = end\n",
        "\n",
        "    plain_text += text[idx:]\n",
        "    return plain_text, bold_positions\n",
        "\n",
        "generated_sections = {}\n",
        "\n",
        "print(\"\\n📄 Generated BRD Sections:\\n\")\n",
        "\n",
        "for section_name in brd_section_prompts.keys():\n",
        "    chain = brd_section_prompts[section_name] | llm\n",
        "    output = chain.invoke({\"context\": context})\n",
        "    raw_content = output.content.strip()\n",
        "\n",
        "    clean_content, bold_ranges = extract_bold_positions(raw_content)\n",
        "    generated_sections[section_name] = (clean_content, bold_ranges)\n",
        "\n",
        "    print(f\"\\n=== {section_name} ===\\n{clean_content}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vbV-iVaH45l0",
        "outputId": "ebdc67d5-4f12-4514-dac2-4d792bf0428d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "📄 Generated BRD Sections:\n",
            "\n",
            "\n",
            "=== Introduction ===\n",
            "This document outlines the requirements for a new Inventory Management System (IMS) designed to modernize our retail chain's inventory processes.  The IMS will address current inefficiencies by streamlining stock tracking, minimizing manual errors, and enhancing reporting functionality.  This will ultimately improve inventory accuracy, reduce operational costs, and provide more effective decision-making data for management.\n",
            "\n",
            "=== Business Goals ===\n",
            "Here are three business goals for the Inventory Management System (IMS) project based on the provided context:\n",
            "\n",
            "1. Improved Inventory Accuracy:  Reduce stock discrepancies and out-of-stocks by automating stock tracking and minimizing manual data entry errors. This will lead to increased sales and reduced losses due to inaccurate inventory counts.\n",
            "\n",
            "2. Enhanced Operational Efficiency: Streamline the inventory management process, freeing up staff time currently spent on manual tasks like stocktaking and reconciliation.  This allows employees to focus on higher-value activities.\n",
            "\n",
            "3. Better Data-Driven Decision Making: Improve the quality and timeliness of inventory reports, providing management with accurate and timely data for informed decisions regarding purchasing, pricing, and stock allocation.  This will lead to optimized inventory levels and improved profitability.\n",
            "\n",
            "=== Functional Requirements ===\n",
            "1. The system shall track inventory levels for each product, differentiating stock by location (e.g., warehouse, store A, store B).  This includes recording receipts, sales, and adjustments to stock levels.\n",
            "\n",
            "2. The system shall allow authorized users to create new stock entries, including product ID, quantity, date received, supplier information, and cost price.  Users shall also be able to modify existing stock entries with appropriate audit trails.\n",
            "\n",
            "3. The system shall generate reports on inventory levels, including low-stock alerts, stock value by location, and sales trends for each product.  Reports shall be exportable in common formats (e.g., CSV, PDF).\n",
            "\n",
            "4. The system shall provide a user-friendly interface for all authorized users to access and interact with the inventory data.  This interface will be accessible via web browser.\n",
            "\n",
            "=== Non-Functional Requirements ===\n",
            "Based on the provided context, here are three non-functional requirements for the Inventory Management System (IMS):\n",
            "\n",
            "* Performance: The system shall process inventory updates and generate reports within 2 seconds for up to 100 concurrent users.  This addresses the speed and responsiveness of the system.  Slower response times could impact productivity and user satisfaction.\n",
            "\n",
            "* Usability: The system shall have an intuitive interface requiring no more than 1 hour of training for new users to achieve proficiency in core tasks (stock entry, reporting, etc.). This focuses on ease of use and learnability, minimizing training costs and user frustration.\n",
            "\n",
            "* Reliability: The system shall have a 99.9% uptime guarantee, with automated backups performed daily and disaster recovery procedures in place. This ensures the system is available when needed and data is protected against loss.  Downtime could lead to significant business disruption.\n",
            "\n",
            "=== Stakeholders ===\n",
            "The key stakeholders involved in the new Inventory Management System (IMS) project for a retail chain are:\n",
            "\n",
            "* Project Sponsor:  Typically a senior executive (e.g., CIO, COO, or CEO).  Their role is to provide overall direction, secure funding, and champion the project within the organization.  They are responsible for approving the project scope, budget, and timelines.\n",
            "\n",
            "* Project Manager: Responsible for the overall planning, execution, monitoring, controlling, and closing of the project.  They manage the project team, track progress against the plan, and resolve issues.\n",
            "\n",
            "* IT Department/Technical Team:  Responsible for the technical aspects of the project, including system design, development, testing, deployment, and ongoing maintenance.  This may include developers, database administrators, network engineers, and security specialists.\n",
            "\n",
            "* Inventory Management Team:  The team currently responsible for managing inventory. Their roles include providing requirements, testing the system, training on the new system, and ultimately using the new IMS daily. They are crucial for ensuring the system meets their needs and integrates smoothly with existing processes.\n",
            "\n",
            "* Retail Store Staff:  The staff in each retail location will be using the IMS daily to update inventory.  Their role is to provide feedback on the usability of the system and to adapt to the new processes.  Their input is critical for ensuring the system is user-friendly and efficient in a real-world retail setting.\n",
            "\n",
            "* Finance Department:  They will be interested in the financial aspects of the project, including cost-benefit analysis, ROI, and the impact on financial reporting.  They will need to approve the budget and review financial reports related to the project.\n",
            "\n",
            "* Vendors/Suppliers (if applicable):  If external vendors are involved in the development or implementation of the IMS, they are stakeholders with responsibilities defined in their contracts.  This could include software developers, system integrators, or hardware providers.\n",
            "\n",
            "* Customers (indirectly): While not directly involved in the project, the ultimate goal is to improve customer experience through better inventory management (e.g., reduced stockouts).  Their satisfaction is an indirect measure of project success.\n",
            "\n",
            "\n",
            "These roles and responsibilities can overlap, and the specific details will vary depending on the size and structure of the retail chain.\n",
            "\n",
            "=== Timeline ===\n",
            "## Proposed Timeline for New Inventory Management System (IMS)\n",
            "\n",
            "This timeline assumes a project duration of 16 weeks.  Dates can be adjusted based on your specific needs.  Assume the project starts on October 2nd, 2023.\n",
            "\n",
            "Phase 1: Project Initiation & Planning (Weeks 1-4)\n",
            "\n",
            "* Week 1 (Oct 2nd - Oct 8th): Project Kick-off Meeting: Define project scope, objectives, and success criteria. Identify key stakeholders and assign roles and responsibilities.  Initial risk assessment.\n",
            "* Week 2 (Oct 9th - Oct 15th): Requirements Gathering & Analysis:  Finalize functional and non-functional requirements (including detailed specifications for reporting).  Document user stories and use cases.\n",
            "* Week 3 (Oct 16th - Oct 22nd): System Design & Architecture: Design the database schema, user interface (UI), and system architecture. Select technologies and tools.\n",
            "* Week 4 (Oct 23rd - Oct 29th):  Development Environment Setup & Procurement: Secure necessary hardware and software. Set up the development environment and version control system.\n",
            "\n",
            "\n",
            "Phase 2: Development & Testing (Weeks 5-12)\n",
            "\n",
            "* Week 5 (Oct 30th - Nov 5th):  Database Development: Develop and test the database schema, including data migration strategy from the existing system (if applicable).\n",
            "* Week 6 (Nov 6th - Nov 12th): Core Functionality Development: Develop core functionalities such as product tracking, stock entry creation/modification, and basic reporting.\n",
            "* Week 7 (Nov 13th - Nov 19th): UI Development: Develop the user interface based on the approved designs.  Conduct usability testing.\n",
            "* Week 8 (Nov 20th - Nov 26th):  Integration & Testing (Unit & Integration): Integrate different modules and conduct unit and integration testing.\n",
            "* Week 9 (Nov 27th - Dec 3rd): Advanced Functionality Development: Develop advanced features (e.g., advanced reporting, low-stock alerts, etc.).\n",
            "* Week 10 (Dec 4th - Dec 10th): User Acceptance Testing (UAT): Conduct UAT with key stakeholders to ensure the system meets requirements.  Address feedback and bug fixes.\n",
            "* Week 11 (Dec 11th - Dec 17th):  Performance & Security Testing: Conduct performance and security testing to identify and address potential issues.\n",
            "* Week 12 (Dec 18th - Dec 24th): Bug Fixing & Refinement: Address any remaining bugs and refine the system based on UAT feedback and testing results.\n",
            "\n",
            "\n",
            "Phase 3: Deployment & Go-Live (Weeks 13-16)\n",
            "\n",
            "* Week 13 (Dec 25th - Dec 31st): Deployment Planning & Preparation: Plan the deployment strategy, including data migration, user training, and communication plan.\n",
            "* Week 14 (Jan 1st - Jan 7th): System Deployment: Deploy the system to the production environment.\n",
            "* Week 15 (Jan 8th - Jan 14th): Post-Deployment Monitoring & Support: Monitor the system performance and provide support to users. Address any post-deployment issues.\n",
            "* Week 16 (Jan 15th - Jan 21st):  Project Closure & Documentation: Finalize project documentation, including user manuals and training materials. Conduct a post-project review.\n",
            "\n",
            "\n",
            "Note: This timeline is a proposal and may need adjustments based on unforeseen challenges or changes in requirements.  Regular progress meetings and risk management are crucial for successful project completion.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 6D: Create and Write to Google Doc\n",
        "\n",
        "!pip install google-api-python-client google-auth google-auth-oauthlib google-auth-httplib2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fRTC7kfH5ECS",
        "outputId": "5f6c599c-43d1-4dca-b69b-03c08ca9e0ab"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-api-python-client in /usr/local/lib/python3.11/dist-packages (2.169.0)\n",
            "Requirement already satisfied: google-auth in /usr/local/lib/python3.11/dist-packages (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (1.2.2)\n",
            "Requirement already satisfied: google-auth-httplib2 in /usr/local/lib/python3.11/dist-packages (0.2.0)\n",
            "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (0.22.0)\n",
            "Requirement already satisfied: google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (2.24.2)\n",
            "Requirement already satisfied: uritemplate<5,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from google-api-python-client) (4.1.1)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib) (2.0.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (5.29.4)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (1.26.1)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.32.3)\n",
            "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in /usr/local/lib/python3.11/dist-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client) (3.2.3)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib) (3.2.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core!=2.0.*,!=2.1.*,!=2.2.*,!=2.3.0,<3.0.0,>=1.31.5->google-api-python-client) (2025.4.26)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 6D: Create and Write to Google Doc with Bullet Formatting\n",
        "from google.oauth2 import service_account\n",
        "from googleapiclient.discovery import build\n",
        "from datetime import datetime\n",
        "\n",
        "# Set up credentials\n",
        "SCOPES = ['https://www.googleapis.com/auth/documents', 'https://www.googleapis.com/auth/drive']\n",
        "SERVICE_ACCOUNT_FILE = 'brd-generation-91eaf7b1a023.json'\n",
        "\n",
        "credentials = service_account.Credentials.from_service_account_file(\n",
        "    SERVICE_ACCOUNT_FILE, scopes=SCOPES)\n",
        "\n",
        "docs_service = build('docs', 'v1', credentials=credentials)\n",
        "drive_service = build('drive', 'v3', credentials=credentials)\n",
        "\n",
        "# Create new doc\n",
        "timestamp = datetime.now().strftime(\"%Y-%m-%d %H:%M\")\n",
        "doc_title = f\"{timestamp} - Generated BRD\"\n",
        "doc = docs_service.documents().create(body={\"title\": doc_title}).execute()\n",
        "document_id = doc.get('documentId')\n",
        "\n",
        "requests = []\n",
        "current_index = 1\n",
        "\n",
        "for section, (content, bold_ranges) in generated_sections.items():\n",
        "    # Insert section heading\n",
        "    requests.append({\n",
        "        'insertText': {\n",
        "            'location': {'index': current_index},\n",
        "            'text': f\"{section}\\n\"\n",
        "        }\n",
        "    })\n",
        "    requests.append({\n",
        "        'updateParagraphStyle': {\n",
        "            'range': {\n",
        "                'startIndex': current_index,\n",
        "                'endIndex': current_index + len(section) + 1\n",
        "            },\n",
        "            'paragraphStyle': {'namedStyleType': 'HEADING_1'},\n",
        "            'fields': 'namedStyleType'\n",
        "        }\n",
        "    })\n",
        "    current_index += len(section) + 1\n",
        "\n",
        "       # Split content into lines and insert each line\n",
        "    lines = content.splitlines()\n",
        "    line_start_indices = []\n",
        "    for line in lines:\n",
        "        is_bullet = line.strip().startswith(\"* \")\n",
        "        text = line.strip()[2:] if is_bullet else line  # Remove \"* \" if it's a bullet\n",
        "        text_with_break = text + \"\\n\"\n",
        "\n",
        "        requests.append({\n",
        "            'insertText': {\n",
        "                'location': {'index': current_index},\n",
        "                'text': text_with_break\n",
        "            }\n",
        "        })\n",
        "\n",
        "        line_start_indices.append((current_index, len(text_with_break), is_bullet))\n",
        "        current_index += len(text_with_break)\n",
        "\n",
        "    # Apply bullet formatting only to lines originally marked with '* '\n",
        "    for start_idx, length, is_bullet in line_start_indices:\n",
        "        if is_bullet:\n",
        "            requests.append({\n",
        "                'createParagraphBullets': {\n",
        "                    'range': {\n",
        "                        'startIndex': start_idx,\n",
        "                        'endIndex': start_idx + length\n",
        "                    },\n",
        "                    'bulletPreset': 'BULLET_DISC_CIRCLE_SQUARE'\n",
        "                }\n",
        "            })\n",
        "\n",
        "\n",
        "# Push all changes\n",
        "docs_service.documents().batchUpdate(\n",
        "    documentId=document_id,\n",
        "    body={'requests': requests}\n",
        ").execute()\n",
        "\n",
        "print(f\"✅ Document created and written: https://docs.google.com/document/d/{document_id}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1IjocL_b5J1S",
        "outputId": "5db4ea98-9f68-4dbe-8a26-21fc03b7d999"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Document created and written: https://docs.google.com/document/d/1BS5VAcjdNTBUwQ0Q3lRgvUF7fUnSbLMCUZhR7ex6qdY\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 6E: Move Document to Specific Google Drive Folder\n",
        "FOLDER_ID = '1WNDymPDORx2bmuUkwwGgbwgEBTMSwG9f'\n",
        "\n",
        "# Move doc to target folder\n",
        "file = drive_service.files().update(\n",
        "    fileId=document_id,\n",
        "    addParents=FOLDER_ID,\n",
        "    removeParents='root',\n",
        "    fields='id, parents'\n",
        ").execute()\n"
      ],
      "metadata": {
        "id": "JENHLaDl8GSJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BJfqHNag8Js5"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}